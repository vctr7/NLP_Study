# Korean Embedding(한국어 임베딩) Study

---

<img src="https://i.imgur.com/j03ENCc.jpg" width="320" height="400"> [Official Website](https://ratsgo.github.io/)


### During NAVER corp. Winter Internship(Jan. 2020 ~ Feb. 2020)


---

## Index

### 01. 서론

- 1.1 임베딩이란

- 1.2 임베딩의 역할

- 1.3 임베딩 기법의 역사와 종류

### 02. 벡터가 어떻게 의미를 가지게 되는가

- 2.1 자연어 계산과 이해

- 2.2 [어떤 단어가 많이 쓰였는가]()

- 2.3 단어가 어떤 순서로 쓰였는가

- 2.4 어떤 단어가 같이 쓰였는가

### 03. 한국어 전처리

- 3.1 [Data Pre-processing]()

- 3.2 지도 학습 기반 형태소 분석

- 3.3 비지도 학습 기반 형태소 분석

### 04. 단어 수준 임베딩

- 4.1 [NPLM]()

- 4.2 [Word2Vec]()

- 4.3 [FastText]()

- 4.4 [Latent Semantic Analysis]()

- 4.5 [GloVe]()

-	4.6 [Swivel]()

- 4.7 어떤 단어 임베딩을 사용할 것인가

- 4.8 가중 임베딩



### 05. 문장수준 임베딩

- 5.1 잠재 의미 분석

- 5.2 Doc2Vec

- 5.3 잠재 디리클레 할당

- 5.4 ELMo

- 5.5 트랜스포머 네트워크

-	5.6 BERT



### 06. 임베딩 파인 튜닝

- 6.1 프리트레인과 파인 튜닝

-	6.2 분류를 위한 파이프라인 만들기

- 6.3 단어 임베딩 활용

- 6.4 ELMo 활용 

- 6.5 BERT 활용

- 6.6 어떤 문장 임베딩을 사용할 것인가



### Appendix

- A 선형대수학 기초

- B 확률론 기초

- C 뉴럴 네트워크 기초

-	D 국어학 기초



## References

- [https://ratsgo.github.io/](https://ratsgo.github.io/)
- [https://github.com/ratsgo/embedding](https://github.com/ratsgo/embedding)




### I do not own any rights.

Copyright  © acorn publishing Co., 2019. All rights reserved. 









